---
title: "R Notebook"
output: 
  html_notebook: 
    number_sections: yes
    toc: yes
---

# Regresja logistyczna -- ocena modelu

```{r pakiety, message=FALSE, warning = FALSE}
library(ResourceSelection) ## hoslem.test -- goodness of fit
library(BaylorEdPsych) ## pseudo R^2
library(car) ## Anova
library(dplyr)
```

## Testowanie hipotez

W pierwszej kolejności w odniesieniu do istotności poszczególnych parametrów, w którym testujemy następujący układ hipotez

$$
\begin{cases}
H_{0}: \beta_k &= 0 \\
H_{1}: \beta_k &\neq 0 \\
\end{cases}
$$

Statystyka Walda (testowa) ma postać następującą:

$$
z_{k} = \frac{\beta_k}{\sqrt{\widehat{VAR}(\beta_k)}} \sim N(0,1)
$$

Więc aby zweryfikować układ hipotez patrzymy na $|Z_k| > Z_{1-\alpha/2}$. Jednakże, w związku z tym, że ten test ma zwykle większy błąd I rodzaju niż przyjęty poziom $\alpha$ stosuje się zwykle test LRT -- Likelihood Ratio Test. Ten test wykorzystywany jest zwykle w odniesieniu 

$$
\Lambda = \frac{\mbox{LogLik modelu ze zmiennymi}}{\mbox{LogLik model ze stałą}} \sim \chi^2_p,
$$

gdzie $p$ to liczba parametrów modelu. W $R$ do tego celu możemy wykorzystać funkcję `stats::anova()` oraz `car::Anova()`. Różnią się tym jak porównywane sa parametry modelu. Załózmy, że mamy model, w którym mamy dwie zmienne $X_1$ oraz $X_2$ i w takiej kolejności zapisujemy model $y \sim X_1 + X_2 + X_1:X_2$ (`:` oznacza interakcję) W tym kontekście rozważmy typy testowanych hipotez

+ Typ 1 (`stats::anova()`) -- sekwencyjnie:
    + najpierw testujemy $X_1$ w odniesieniu do modelu ze stałą,
    + potem testujemy $X_2$ w odniesieniu do modelu z $X_1$,
    + na końcu testujemy $X_1:X_2$ w odniesieniu do modelu z $X_1$ oraz $X_2$.
+ Typ 2 (`car::Anova(Y ~ X_1*X_2, type = 2)`):
    + najpierw testujemy $X_1$ w odniesieniu do modelu z $X_2$,
    + potem testujemy $X_2$ w odniesieniu do modelu z $X_1$,
    + na końcu testujemy $X_1:X_2$ w odniesieniu do modelu z $X_1$ oraz $X_2$.
+ Typ 3  (`car::Anova(Y ~ X_1*X_2, type = 3, contrasts=list(X_1=contr.sum, X_2=contr.sum))`):
    + najpierw testujemy $X_1$ w odniesieniu do modelu z $X_2$ oraz $X_1:X_2$,
    + potem testujemy $X_2$ w odniesieniu do modelu z $X_1$ oraz $X_1:X_2$,
    + na końcu testujemy $X_1:X_2$ w odniesieniu do modelu z $X_1$ oraz $X_2$.
    

W literaturze jest na ten temat spora dysuksja. Według niektórych warto skorzystać z typu 2. Aby przeprowadzić w R procedurę testu LRT należy użyć następujących kodów:

+ `stats::anova(model, test = 'Chisq')` lub `stats::anova(model1, model2,..,modelK, test = 'Chisq')` -- Typ 1
+ `stats::Anova(model, test = 'LR')` -- Typ 1

## Miary jakości modelu

McFadden -- McFadden Pseudo-R^2 -- Nie jest to jednak współczynnik unormowany w przedziale [0, 1] a jego maksymalna wartość jest mniejsza od 1. Przyjmuje się przy tym, że wartości z przedziału 0,2-0,4 są w zupełności zadowalające.

$$
R^2_{McF} = 1 – ln(L_{M}) / ln(L_{0})
$$

Adj.McFadden	 -- McFadden Adjusted Pseudo-R^2

$$
R^2_{adj-McF} = 1 – ln(L_{M} - p - 1) / ln(L_{0})
$$

Cox.Snell	 -- Cox and Snell Pseudo-R^2 (also known as ML Pseudo-R^2)

$$
R^2_{C\&S} = 1 – exp\left( \frac{-2ln(L_0) + 2ln(L_M)}{n}\right)
$$

Nagelkerke	-- Nagelkerke PseudoR^2 -- unormowany do przedziału [0,1]

$$
R^2_N = 1 - \frac{1 - exp^{(-2/n (ln(L_M) - lm(L_0)))}}{1 - exp^{-2/nln(L_0)}}
$$

Pozostałe:

+ McKelvey.Zavoina	-- McKelvey and Zavoina Pseudo-R^2
+ Effron	 -- Effron Pseudo-R^2
+ Count	 -- Count Pseudo-R^2, number of correctly classified cases, using $\hat{\pi}> .50$ as the cutoff
+ Adj.Count	-- Adjusted Count Pseudo-R^2


### The Hosmer-Lemeshow test

Statystyka Hosmera-Lemeshow'a jakości dopasowania dana jest:


$$
H=\sum_{g=1}^{G}
\left\{
\frac{(O_{1g}-E_{1g})^{2}}{E_{1g}}+
\frac{(O_{0g}-E_{0g})^{2}}{E_{0g}}
\right\}
=\sum_{g=1}^{G}
\left\{
\frac {(O_{1g}-E_{1g})^{2}}{N_{g}\pi _{g}}+
\frac {(N_{g}-O_{1g}-(N_{g}-E_{1g}))^{2}}{N_{g}(1-\pi _{g})}
\right\}
=
\sum _{g=1}^{G}
\frac {(O_{1g}-E_{1g})^{2}}{N_{g}\pi_{g}(1-\pi _{g})} \sim \chi^2_{G-2}
$$

gdzie: $O_{1g}$ to wartości obserwowane dla $Y=1$, $E_{1g}$ to wartości oczekiwane dla $Y=1$, $O_{0g}$ to wartości obserwowane dla $Y=0$, $E_{0g}$ to wartości oczekiwane dla $Y=0$, $N_{g}$ to liczba obserwacji oraz $\pi_{g}$ jest oszacowaniem ryzyka w $g$-tym decylu, a $G$ to liczba grup.

Procedura jest następująca:

1. obliczamy prawdopodobieństwo sukcesu dla wszystkich obserwacji,
2. sortujemy według prawdopodobieństwa od najmniejszych do największych
3. dzielimy na $G$ precentyli (decyli)
4. tworzymy tabelę wartości obserwowanych i oczekiwanych
5. obliczamy wartość statystyki HM
6. obliczamy p-value


### Kryteria informacyjne

AIC, BIC, AICc, cAIC i inne (im mniejsze tym lepsze) -- ale trzeba uważać.

### Dobór zmiennych

Pakiet `boruta`, `glmulti`, czy `MuMIn`, LASSO `glmnet`

## Przykład 

### Wczytanie danych

```{r}
load('../data/diagnoza2015.rdata')
diagnoza2015$internet <- ifelse(diagnoza2015$internet == 1, 1, 0)
diagnoza2015$bezrob <- ifelse(diagnoza2015$czy_rej_pup==1,1,0)

## nadajemy etykiety

diagnoza2015$plec <- factor(
  x = diagnoza2015$plec,
  levels = 1:2,
  labels = c('Mezczyzna','Kobieta'),
  ordered = FALSE
)

diagnoza2015$klm <- factor(
  x = diagnoza2015$klm,
  levels = 1:6,
  labels = c('500k+', '200k-500k','100k-200k', '20k-100k','ponizej 20k', 'wies'),
  ordered = FALSE
)

diagnoza2015$klm <- relevel(diagnoza2015$klm,ref = 'wies')

diagnoza2015$woj <- factor(
  x = diagnoza2015$woj,
  levels = seq(2,32,2),
  labels = c(
    'Dolnośląskie','Kujawsko-Pomorskie',
    'Lubelskie','Lubuskie','Łódzkie',
    'Małopolskie','Mazowieckie','Opolskie','Podkarpackie',
    'Podlaskie','Pomorskie','Śląskie',
    'Świętokrzyskie','Warmińsko-Mazurskie',
    'Wielkopolskie','Zachodniopomorskie'),
  ordered = FALSE)

diagnoza2015
```

## Modelowanie

### Pierwszy model z wykorzystaniem funkcji `glm`

```{r}
model1 <- glm(internet ~ woj + klm + plec, data = diagnoza2015, family = binomial())
summary(model1)
```

### Drugi model, dodajemy wiek

```{r}
model2 <- update(model1, .~. + wiek)
summary(model2)
```

### Trzeci model -- dodajemy interakcję między KLM a płcią

```{r}
model3 <- update(model2, .~. + klm:plec)
summary(model3)
```

### Porównamy istotność całych zmiennych -- czy poprawiają? 

Najpierw Anova typ I
```{r}
## ANOVA -- typ I
anova(model1, test = 'Chisq')
anova(model2, test = 'Chisq')
anova(model3, test = 'Chisq')
```

Teraz zobaczmy na anovę typu II i III

```{r}
Anova(model1, type = 'II')
Anova(model2, type = 'II')
Anova(model3, type = 'II')
```

I na końcu Anova typ 3 -- jedynie ma sens w przypadku modelu z interakcjami, tu zobaczymy różnicę

```{r}
Anova(model3, type = 'III')
```


```{r}
anova(model1, model2, model3, test = 'LRT')
```

## Jakość modelu

### Test Hosmera and Lemeshow'a

```{r}
hoslem.test(diagnoza2015$internet, fitted(model1), g = 10)
hoslem.test(diagnoza2015$internet, fitted(model2), g = 10)
hoslem.test(diagnoza2015$internet, fitted(model3), g = 10)
```

### Miary PseudoR2

```{r}
wynik <- sapply(list(model1,model2,model3), PseudoR2)
rownames(wynik)
wynik['Nagelkerke',]
wynik['Corrected.AIC',]
```

## Uwaga -- interakcje z poziomami, których nie ma

Rozważmy model

```{r}
m1 <- glm(internet ~ woj*klm, data = diagnoza2015, family = binomial())
summary(m1)
```

Pojawiają się dziwne wartości

```
wojOpolskie:klm500k+                         NA         NA      NA       NA    
wojPodkarpackie:klm500k+                     NA         NA      NA       NA    
wojPodlaskie:klm500k+                        NA         NA      NA       NA    
wojPomorskie:klm500k+                        NA         NA      NA       NA    
wojŚląskie:klm500k+                          NA         NA      NA       NA    
wojŚwiętokrzyskie:klm500k+                   NA         NA      NA       NA    
wojWarmińsko-Mazurskie:klm500k+              NA         NA      NA       NA 
```

Dlaczego? Dla niektórych kategorii mamy zera.

```{r}
xtabs(~woj + klm, diagnoza2015)
```



